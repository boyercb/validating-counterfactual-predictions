
\section{Time-fixed treatment initiation} \label{sec:appendixa}

    \subsection{Tailoring models for counterfactual predictions}\label{sec:model_proof}
    Our goal is to build a model that targets the expected potential outcome under a hypothetical intervention, e.g. the parametric model 
    $$\E[Y^a \mid X^*] = \mu_{\beta}(X^*).$$
    However, we do not observe $Y^a$ for all individuals. Nonetheless, as the following theorem shows, targets like $\E[Y^a \mid X^*]$ are identifiable from the observed data $(X, A, Y)$ under certain assumptions. 
    
    \begin{theorem}
     Under conditions A1-A3 in section \ref{sec:identifiability}, $\E[Y^a \mid X^*]$ is identified by the observed data functionals
    \begin{equation}
        \E[Y^a \mid X^*] = \E[\E[Y \mid X, A = a, D_{train} = 1] \mid X^*, D_{train} = 1]
    \end{equation}
    and
    \begin{equation}
        \E[Y^a \mid X^*] = \E\left[\frac{I(A = a)}{\Pr[A = a \mid X, D_{train} = 1]} Y \mid X^*, D_{train} = 1\right]
    \end{equation}
    in which case we can build a model for $\E[Y^a \mid X^*]$ by targeting either estimand in the training dataset.
    \end{theorem}
    
    \begin{proof}
        For the first representation we have 
        \begin{align*}
            \E[Y^a \mid X^*] & = \E[Y^a \mid X^*, D_{train} = 1] \\
            & = \E(\E[Y^a\mid X, D_{train} = 1] \mid X^*, D_{train} = 1) \\
            & = \E(\E[Y^a\mid X, A = a, D_{train} = 1] \mid X^*, D_{train} = 1) \\
            & = \E(\E[Y \mid X, A = a, D_{train} = 1] \mid X^*, D_{train} = 1) 
        \end{align*}
        where the first line follows from the random sampling of the training set, the second from the law of iterated expectations, the third from the exchangeability condition A1, and the fourth from the consistency condition A2. Recall that $X^*$ is a subset of $X$. For the second representation, we show that it is equivalent to the first 
        \begin{align*}
            \E[Y^a \mid X^*] &= \E(\E[Y \mid X, A = a, D_{train} = 1] \mid X^*, D_{train} = 1)  \\
            &= \E\left(\E\left[\frac{I(A = a)}{\Pr[A = a \mid X,D_{train} = 1]}Y \mid X,D_{train} = 1\right] \mid X^*, D_{train} = 1\right)\\
            %&= \E\left(\frac{I(A = a)}{\Pr[A = a \mid X,D_{train} = 1]}\E\left[Y \mid X,D_{train} = 1\right] \mid X^*, D_{train} = 1\right)\\
            &= \E\left[\frac{I(A = a)}{\Pr[A = a \mid X,D_{train} = 1]}Y \mid X^*, D_{train} = 1\right]
        \end{align*}
        where the second line follows from the definition of conditional expectation, and the last reverses the law of iterated expectations.
    \end{proof}

    \subsection{Identification of general loss functions}\label{sec:tf_proof}
    Many common model performance measures, such as the mean squared error, Brier score, and absolute error are special cases of a generic loss function $L(Y, \mu_{\widehat{\beta}}(X^*))$. To assess the performance of counterfactual predictions, we would like to estimate 
    $$\psi_{\widehat{\beta}} = \E[L(Y^a, \mu_{\widehat{\beta}}(X^*))]$$
    where $Y^a$ is not observed for all individuals. The following theorem states that, under the conditions of section \ref{sec:identifiability}, $\psi_{\widehat{\beta}}$ is identified using the observed data alone. 
    \begin{theorem}
        Under conditions A1-A3 in section \ref{sec:identifiability} and the time-fixed setup described in section \ref{sec:setup}, the expected loss is identified by the functionals
        \begin{equation}\label{eqn:app_cl_estimand}
            \psi_{\widehat{\beta}} = \E\left(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid X, A=a, D_{test} = 1] \mid D_{test} = 1\right)
        \end{equation}
        and 
        \begin{equation}\label{eqn:app_ipw_estimand}
            \psi_{\widehat{\beta}} = \E\left[\frac{I(A = a)}{\Pr[A = a \mid X, D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right]
        \end{equation}
        in the test set for generic counterfactual loss function $L(Y^{a}, \mu_{\widehat{\beta}})$.
    \end{theorem}
    

    \begin{proof}
        For the first representation we have 
        \begin{align*}
            \psi_{\widehat{\beta}} &= \E[L\{Y^{a}, \mu_{\widehat{\beta}}(X^*)\}] \\
            & = \E[L\{Y^{a}, \mu_{\widehat{\beta}}(X^*)\}\mid D_{test} = 1] \\
            & = \E(\E[L\{Y^{a}, \mu_{\widehat{\beta}}(X^*)\}\mid X, D_{test} = 1] \mid D_{test} = 1) \\
            & = \E(\E[L\{Y^{a}, \mu_{\widehat{\beta}}(X^*)\}\mid X, A = a, D_{test} = 1] \mid D_{test} = 1) \\
            & = \E(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\}\mid X, A = a, D_{test} = 1] \mid D_{test} = 1) 
        \end{align*}
        where the first line follows from the definition of $\psi_{\widehat{\beta}}$, the second from random sampling of the test set, the third from the law of iterated expectations, the fourth from the exchangeability condition A1, and the fifth from the consistency condition A2. Recall that $X^*$ is a subset of $X$. For the second representation, we show that it is equivalent to the first 
        \begin{align*}
            \psi_{\widehat{\beta}} &= \E(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\}\mid X,A = a, D_{test} = 1] \mid D_{test} = 1) \\
            &= \E\left(\E\left[\frac{I(A = a)}{\Pr[A = a \mid X,D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid X,D_{test} = 1\right] \mid D_{test} = 1\right)\\
            % &= \E\left(\frac{I(A = a)}{\Pr[A = a \mid X,D_{test} = 1]}\E\left[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid X,D_{test} = 1\right] \mid D_{test} = 1\right)\\
            &= \E\left[\frac{I(A = a)}{\Pr[A = a \mid X,D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right]
        \end{align*}
        where the second line follows from the definition of conditional expectation, and the last reverses the law of iterated expectations.
    \end{proof}
    
    \subsection{Plug-in estimation}
    Using sample analogs for the identified expressions \ref{eqn:app_cl_estimand} and \ref{eqn:app_ipw_estimand}, we obtain two plug-in estimators for the expected loss for a generalized loss function
    \begin{equation*}
        \widehat{\psi}_{CL} = \frac{1}{n_{test}}\sum_{i=1}^nI(D_{test, i} = 1)\widehat{h}_a(X_i)
    \end{equation*}
    and 
    \begin{equation*}
        \widehat{\psi}_{IPW} = \frac{1}{n_{test}} \sum_{i=1}^n \frac{I(A_i = a, D_{test, i} = 1)}{ \widehat{e}_a(X_i)} L\{Y_i, \mu_{\widehat{\beta}}(X^*_i)\}
    \end{equation*}
    where $\widehat{h}_a(X)$ is an estimator for $\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\}\mid X,A = a, D_{test} = 1]$ and $\widehat{e}_a(X)$ is an estimator for $\Pr[A = a \mid X,D_{test} = 1]$. Using the terminology in Morrison et al., we call the first plug-in estimator the conditional loss estimator $ \widehat{\psi}_{CL}$ and the second the inverse probability weighted estimator $\widehat{\psi}_{IPW}$. 

    \subsection{Random and dynamic regimes}\label{sec:randomdynamic}
    Above we consider static interventions which set treatment $A$ to a particular value $a$. We might also consider interventions which probabilistically set $A$ based on a known density, possibly conditional on pre-treatment covariates, e.g. $f^{int}(A \mid X)$. For instance, instead of a counterfactual prediction if everyone or no one had been treated, we may be interested in the prediction if 20\% or 50\% were treated. We term such an intervention a \textit{random} intervention to contrast it with \textit{static} interventions considered previously. Random interventions are closer to the counterfactual interventions of interest under dataset shift which may be approximated as probabilistic changes in the natural course of treatment due to changes in guidelines or prescribing patterns or the wider-availability. For general counterfactual loss function $L\{Y^{g}, \mu_{\widehat{\beta}}\}$, the expected loss under a random intervention is identified by the functionals
    \begin{equation}\label{eqn:rand_cl_estimand}
        \psi_{\widehat{\beta}} = \E\left\{\E_{f^{int}}\left(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid X, A, D_{test} = 1] \mid D_{test} = 1\right)\right\}
    \end{equation}
    and 
    \begin{equation}\label{eqn:rand_ipw_estimand}
        \psi_{\widehat{\beta}} = \E_{f^{int}}\left[\frac{I(A = a)}{\Pr[A = a \mid X, D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right]
    \end{equation}
    in the test set under the time-fixed setup described in section \ref{sec:setup}. The primary difference between these expressions and the ones in section A.1. is that the expectation is taken with respect to the intervention density. 

% \subsection{Propensity score interventions}

\section{Time-varying treatment initiation}\label{sec:timevarying}
\subsection{Set up}
Here we extend the set up of section \ref{sec:setup} in the case that treatment initiation is time-varying over the follow up period. We now observe $n$ i.i.d. longitudinal samples $\{O_i\}_{i=1}^n$ from a source population. For each observation, let 
\[O =(\overline{X}_K, \overline{A}_K, Y_{K+1})\]
where $X_k$ is a vector of covariates, $A_k$ is an indicator of treatment, and $Y_k$ is an event indicator all measured at time $k$, where $k \in \{0,1,\ldots, K\}$. Overbars denote the full history of a variable, such that $\overline{X}_k = (X_0,\dots, X_k)$. Again we assume the goal is to build a prediction model for end of follow up outcome $Y_{K+1}$ conditional on baseline covariates $X^*$ which are now a subset of baseline covariates $X_0$, i.e. $X^* \subset X_0$. An example DAG for a two time point process is shown in Figure \ref{fig:dag2}.

We would like to assess the performance of the model in a counterfactual version of the source population in which a new treatment policy is implemented. As previously, $Y^a$ is the potential outcome under an intervention which sets treatment $A$ to $a$. For a sequence of time-varying treatments $\overline{A}_k$, we further define a \textit{treatment regime} as a collection of functions $\{g_k(\overline{a}_{k-1}, \overline{x}_k): k=0,\ldots, K\}$ for determining treatment assignment at each time $k$, possibly based on past treatment and covariate history. For a hypothetical treatment regime $g$, we would like to determine the performance of fitted model $\mu_{\widehat{\beta}}(X^*)$ under the new regime by estimating the expected loss 
$$\psi_{\widehat{\beta}} = \E[L\{Y^g, \mu_{\widehat{\beta}}(X^*)\}]$$
for generalized loss function $L\{Y^g, \mu_{\widehat{\beta}}(X^*)\}$.

\begin{figure}[p]
    \centering
    \begin{subfigure}{\linewidth}
        \centering
        \begin{tikzpicture}[> = stealth, shorten > = 1pt, auto, node distance = 2.5cm, inner sep = 0pt,minimum size = 0.5pt, semithick]
            \tikzstyle{every state}=[
              draw = white,
              fill = white
            ]
            \node[state] (l0) {$L_{0}$};
            \node[state] (a0) [right of=l0] {$A_{0}$};
            \node[state] (l1) [right of=a0] {$L_1$};
            \node[state] (a1) [right of=l1] {$A_1$};
            \node[state] (y1) [right of=a1] {$Y_2$};
            \node[state] (u0) [below of=l0] {$U$};
            \node[state] (p0) [below of=u0] {$P_{0}$};
            \node[state] (b0) [right of=p0] {};
            \node[state] (b1) [right of=b0] {};
            \node[state] (p1) [right of=b1] {$P_{1}$};
            
            \path[->] (l0) edge node {} (a0);
            \path[->] (l0) edge node {} (p1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (l1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (a1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (y1);
        
            \path[->] (a0) edge node {} (p1);
            \path[->] (a0) edge node {} (l1);
            \path[->] (a0) edge [out=20, in=160, looseness=1]  node {} (a1);
            \path[->] (a0) edge [out=20, in=160, looseness=1]  node {} (y1);
            
            \path[->] (p0) edge node {} (p1);
            \path[->] (p0) edge node {} (y1);
            
            \path[->] (p1) edge node {} (y1);
                
            \path[->] (l1) edge node {} (a1);
            \path[->] (l1) edge [out=20, in=160, looseness=1]  node {} (y1);
            
            \path[->] (a1) edge node {} (y1);
        
            \path[->] (u0) edge node {} (y1);
            \path[->] (u0) edge node {} (l0);
            \path[->] (u0) edge node {} (l1);
            \end{tikzpicture}
            \caption{Example two time point directed acyclic graph for prediction.}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \begin{tikzpicture}[> = stealth, shorten > = 1pt, auto, node distance = 2.5cm, inner sep = 0pt,minimum size = 0.5pt, semithick]
            \tikzstyle{every state}=[
              draw = white,
              fill = white
            ]
            \node[state] (l0) {$L_{0}$};
            \node[state] (a0) [right of=l0] {$A_{0} \mid a_0$};
            \node[state] (l1) [right of=a0] {$L^{a_0}_1$};
            \node[state] (a1) [right of=l1] {$A^{a_0}_1 \mid a_1$};
            \node[state] (y1) [right of=a1] {$Y^{a_0, a_1}_2$};
            \node[state] (u0) [below of=l0] {$U$};
            \node[state] (p0) [below of=u0] {$P_{0}$};
            \node[state] (b0) [right of=p0] {};
            \node[state] (b1) [right of=b0] {};
            \node[state] (p1) [right of=b1] {$P^{a_0}_{1}$};
            
            \path[->] (l0) edge node {} (a0);
            \path[->] (l0) edge node {} (p1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (l1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (a1);
            \path[->] (l0) edge [out=20, in=160, looseness=1] node {} (y1);
        
            \path[->] (a0) edge node {} (p1);
            \path[->] (a0) edge node {} (l1);
            \path[->] (a0) edge [out=20, in=160, looseness=1]  node {} (a1);
            \path[->] (a0) edge [out=20, in=160, looseness=1]  node {} (y1);
            
            \path[->] (p0) edge node {} (p1);
            \path[->] (p0) edge node {} (y1);
            
            \path[->] (p1) edge node {} (y1);
                
            \path[->] (l1) edge node {} (a1);
            \path[->] (l1) edge [out=20, in=160, looseness=1]  node {} (y1);
            
            \path[->] (a1) edge node {} (y1);
        
            \path[->] (u0) edge node {} (y1);
            \path[->] (u0) edge node {} (l0);
            \path[->] (u0) edge node {} (l1);
            \end{tikzpicture}
            \caption{Single world intervention graph of intervention on $A_0$ and $A_1$.}
    \end{subfigure}
    \caption{Example directed acyclic graph (DAG) and single world intervention graph (SWIG) for a two time point process.}
    \label{fig:dag2}
\end{figure}

\subsection{Identifiability conditions}
We now consider modified identifiability conditions under time-varying treatment initiation. For all $k$ from 0 to $K$, we require
\begin{enumerate}
    \item[B1.] \textit{Exchangeability:} $Y^g_{K+1} \perp \!\!\! \perp A_k \mid \overline{X}_k, \overline{A}_{k-1}$
    \item[B2.] \textit{Consistency:} $Y_{K+1} = Y^g_{K+1}$\text{ and } $\overline{X}_{k} = \overline{X}^g_{k}$ \text{ if } $\overline{A}_k = \overline{a}_k^g$
    \item[B3.] \textit{Positivity:} $1 > \Pr[A_k = a_k \mid \overline{X}_k = \overline{x}_k, \overline{A}_{k -1} = \overline{a}_{k-1}] > 0$
\end{enumerate}

\subsection{Identification of general loss functions}
The following theorem extends Theorem 2 to the case of a time-varying treatment. 
\begin{theorem}
    Under conditions B1-B3 above, the expected counterfactual loss under time-varying regime $g$ is identified by the functionals
    \begin{align}\label{eqn:cl_tv_estimand}
    \begin{split}
        \psi_{\widehat{\beta}} &= \E_{X_0}\bigg[\E_{X_1}\bigg\{\ldots \E_{X_{K-1}}\bigg(\E_{X_{K}}[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1] \\
        & \qquad \big\vert\; \overline{X}_{K-1}, \overline{A}_{K-1}=\overline{a}^g_{K-1}, D_{test} = 1\bigg) \ldots \;\big\vert\; X_{0}, A_{0}=a^g_{0}, D_{test} = 1\bigg\}\;\big\vert\; D_{test} = 1\bigg]
    \end{split}
    \end{align}
and 
    \begin{equation}\label{eqn:ipw_tv_estimand}
        \psi_{\widehat{\beta}} = \E\left[\frac{I(\overline{A}_K = \overline{a}^g_K, D_{test} = 1)}{\prod_{k=0}^K\Pr[A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right]
    \end{equation}
in the test set for general loss function $L\{Y^{g}, \mu_{\widehat{\beta}}\}$, where the first expression is a sequence of iterated expectations and the second is an inverse-probability weighted expectation.
\end{theorem}

\begin{proof}
    For the first representation we have 
    \begin{align*}
        \psi_{\widehat{\beta}} &= \E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}] \\
        & = \E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid D_{test} = 1] \\
        & = \E(\E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid X_0, D_{test} = 1] \mid D_{test} = 1) \\
        & = \E(\E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid X_0, A_0 = a^g_0, D_{test} = 1] \mid D_{test} = 1) 
    \end{align*}
    where the first line follows from the definition of $\psi_{\widehat{\beta}}$, the second from random sampling of the test set, the third from the law of iterated expectations, and the fourth from the exchangeability condition B1. Arguing recursively from $k = 0$ to $K$, we can repeatedly invoke iterated expectations and exchanageability to insert $\overline{X}_k$ and $\overline{A}_k = \overline{a}^g_k$, such that
    \begin{align*}
        \psi_{\widehat{\beta}} &= \E_{X_0}\bigg[\E_{X_1}\bigg\{\ldots \E_{X_{K-1}}\bigg(E_{X_{K}}[L\{Y^g, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1] \\
        & \qquad \big\vert\; \overline{X}_{K-1}, \overline{A}_{K-1}=\overline{a}^g_{K-1}, D_{test} = 1\bigg) \ldots \;\big\vert\; X_{0}, A_{0}=a^g_{0}, D_{test} = 1\bigg\}\;\big\vert\; D_{test} = 1\bigg]\\
        &= \E_{X_0}\bigg[\E_{X_1}\bigg\{\ldots \E_{X_{K-1}}\bigg(\E_{X_{K}}[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1] \\
        & \qquad \big\vert\; \overline{X}_{K-1}, \overline{A}_{K-1}=\overline{a}^g_{K-1}, D_{test} = 1\bigg) \ldots \;\big\vert\; X_{0}, A_{0}=a^g_{0}, D_{test} = 1\bigg\}\;\big\vert\; D_{test} = 1\bigg]
    \end{align*}
    where the last line follows by consistency condition B2. For the second representation, note that for the inner most expectations we can proceed as previously
    \begin{align*}
        & \E(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_k=\overline{a}^g_K, D_{test} = 1] \mid \overline{X}_{K-1}, \overline{A}_{k-1}=\overline{a}^g_{K-1}, D_{test} = 1) \\
        &= \E\left(\E\left[W_K L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1\right] \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right)\\
        &= \E\left(W_K \E\left[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1\right] \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right)\\
        &= \E\left[W_K L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right]
    \end{align*}
    where the second line follows from the definition of conditional expectation, the third removes the constant fraction outside expectation, and the last reverses the law of iterated expectations and where 
    $$W_K = \frac{I(A_K = a_K^g, D_{test} = 1)}{\Pr[A_K = a_K^g \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1]}$$
    Arguing recursively from $k = 0$ to $K$, we get
    \begin{align*}
        \psi_{\widehat{\beta}} &= \E\left[\frac{I(\overline{A}_K = \overline{a}^g_K, D_{test} = 1)}{\prod_{k=0}^K\Pr[A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1]}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right] 
    \end{align*}
    which is the inverse-probability weighted representation with weights equal to 
    $$W_k = \frac{I(\overline{A}_K = \overline{a}^g_K, D_{test} = 1)}{\prod_{k=0}^K\Pr[A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1]}$$
    .
\end{proof}

\subsection{Plug-in estimation}

Using sample analogs for the identified expressions \ref{eqn:cl_tv_estimand} and \ref{eqn:ipw_tv_estimand}, we obtain two plug-in estimators for the expected counterfactual loss under a generalized loss function
\begin{equation*}
    \widehat{\psi}_{CL} = \frac{1}{n_{test}}\sum_{i=1}^nI(D_{test, i} = 1)\widehat{h}_{a_0}(X_i)
\end{equation*}
and 
\begin{equation*}
    \widehat{\psi}_{IPW} = \frac{1}{n_{test}}\sum_{i=1}^n \frac{I(\overline{A}_{K,i} = \overline{a}^g_{K,i}, D_{test,i} = 1)}{\prod_{k=0}^K \widehat{e}_{a_k}(X_i)} L\{Y_i, \mu_{\widehat{\beta}}(X^*_i)\}
\end{equation*}
where $h_{t+1} = L\{Y, \mu_{\widehat{\beta}}(X^*_i)\}$ and $h_{a_0}(X)$ is recursively defined for $t$ = $K, \ldots, 0$
\[h_{a_t} : (x_t, a_t) \E[ h_{a_{t+1}}(X_{t+1}) \mid \overline{X}_t, \overline{A}_t = \overline{a}^g_t]\]

$\widehat{h}_a(X)$ is an estimator for $\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\}\mid X,A = a, D_{test} = 1]$ and $\widehat{e}_{a_k}(X)$ is an estimator for $\Pr[A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1]$. Note that as the number of time points (i.e. $K$) increases, the proportion in the test set who actually follow the regime of interest, i.e. those for whom $I(\overline{A}_K = \overline{a}^g_K, D_{test,i} = 1)=1$ may be prohibitively small, in which case plug-in estimation may not be feasible. In this case, additional modeling assumptions will be necessary to borrow information from other regimes.
\newpage

% \section{Survival outcome}
% \subsection{Set up}

% Here we further extend the setup of section \ref{sec:timevarying} to the case of a survival outcome with right censoring. As before, we observe i.i.d. longitudinal samples $\{O_i\}_{i=1}^n$ from $n$ participants following distribution $\mathbb{P}$. For each observation, let 
% \[O_i =(\overline{X}_K, \overline{A}_K, \overline{C}_{K+1}, \overline{Y}_{K+1}, T)\]
% where $X_k$ and $A_k$ are defined as previously, $C_{k+1}$ is an indicator of loss to follow-up by time $k+1$, $Y_{k+1}$ is an indicator that the outcome of interest has occurred by time $k + 1$, and $T$ is the failure time for outcome $Y_{k+1}$ that is either exactly observed or interval censored. Overbars still denote past history of a variable such that $\overline{X}_k = (X_0,\dots, X_k)$.

% By definition $C_0 \equiv 0$ and $Y_0 \equiv 0$ as we restrict to those who are uncensored and event-free at the start of follow up. By convention, when $Y_k = 1$ then $\underline{Y}_{k+1} = 1$, $\underline{V}_{k+1} = 0$, and $\underline{C}_{k+1} = 0$, and likewise when $C_k = 1$ then $\underline{Y}_{k+1} = 0$, $\underline{V}_{k+1} = 0$, and $\underline{C}_{k+1} = 1$. An example directed acyclic graph for a two time point process under the above process is shown in Figure \ref{fig:dag_survival}.

% In the survival setting, the analyst typically builds a prediction model targeting the conditional cumulative incidence, $\Pr(T \leq t \mid X^*)$, conditional on covariates $X^*$ for some $t$ representing the desired prediction horizon. Note, as defined above, $\Pr(T \leq t \mid X^*) = \Pr(Y_{k+1} = 1 \mid X^*)$ when $k + 1 = t$. To determine the performance of fitted model $\mu_{\widehat{\beta}}(X^*)$ under a counterfactual regime $g$, we'd like to estimate the expected loss 
% $$\psi_{\widehat{\beta}} = \E[L\{I(T^g\leq t), \mu_{\widehat{\beta}}(X^*)\}]$$
% for generalized loss function $L\{I(T^g\leq t), \mu_{\widehat{\beta}}(X^*)\}$. This is equivalent to $\E[L\{Y^g_{K+1}, \mu_{\widehat{\beta}}(X^*)\}]$ for suitably chosen $K$. Under right censoring, we can extend this to 
% $$\psi_{\widehat{\beta}} = \E[L\{I(T^{g,\overline{c}=0}\leq t), \mu_{\widehat{\beta}}(X^*)\}]$$
% where $\overline{c}=0$ denotes the counterfactual outcome if no one was censored. This is again equivalent to $\E[L\{Y^{g,\overline{c}=0}_{K+1}, \mu_{\widehat{\beta}}(X^*)\}]$ for suitably chosen $K$.


% \begin{figure}[p]
%     \centering
%     \begin{subfigure}{\linewidth}
%     \centering
%     \begin{tikzpicture}[> = stealth, shorten > = 1pt, auto, node distance = 2cm, inner sep = 0pt,minimum size = 0.5pt, semithick]
%     \tikzstyle{every state}=[
%       draw = white,
%       fill = white
%     ]
%     \nod\E[state] (l0) {$L_0$};
%     \nod\E[state] (a0) [right of=l0] {$A_0$};
%     \nod\E[state] (c0) [right of=a0] {$C_1$};
%     \nod\E[state] (y1) [right of=c0] {$Y_1$};
%     \nod\E[state] (l1) [right of=y1] {$L_1$};
%     \nod\E[state] (a1) [right of=l1] {$A_1$};
%     \nod\E[state] (c1) [right of=a1] {$C_2$};
%     \nod\E[state] (y2) [right of=c1] {$Y_2$};
%     \nod\E[state] (p0) [below of=l0] {$P_0$};
%     \nod\E[state] (b0) [right of=p0] {};
%     \nod\E[state] (b1) [right of=b0] {};
%     \nod\E[state] (b2) [right of=b1] {};
%     \nod\E[state] (p1) [right of=b2] {$P_1$};
%     \nod\E[state] (u0) [below of=b2] {$U$};
    
%     \path[->] (l0) edge node {} (a0);
%     \path[->] (l0) edge node {} (p1);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (c0);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (y1);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (l1);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (c1);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (a1);
%     \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (y2);

%     \path[->] (a0) edge node {} (p1);
%     \path[->] (a0) edge node {} (c0);
%     \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (y1);
%     \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (l1);
%     \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%     \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%     \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (y2);
    
%     \path[->] (c0) edge node {} (p1);
%     \path[->] (c0) edge node {} (y1);
%     \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (l1);
%     \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%     \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%     \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (y2);

%     \path[->] (y1) edge node {} (p1);
%     \path[->] (y1) edge node {} (l1);
%     \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%     \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%     \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (y2);
    
%     \path[->] (p0) edge node {} (p1);
%     \path[->] (p0) edge node {} (y1);
%     \path[->] (p0) edge node {} (y2);

%     \path[->] (p1) edge node {} (y2);
        
%     \path[->] (l1) edge node {} (a1);
%     \path[->] (l1) edge [out=20, in=160, looseness=1.5] node {} (c1);
%     \path[->] (l1) edge [out=20, in=160, looseness=1.5] node {} (y2);
    
%     \path[->] (a1) edge node {} (c1);
%     \path[->] (a1) edge [out=20, in=160, looseness=1.5] node {} (y2);

%     \path[->] (c1) edge node {} (y2);

%     \path[->] (u0) edge node {} (y1);
%     \path[->] (u0) edge node {} (y2);
%     \path[->] (u0) edge node {} (l0);
%     \path[->] (u0) edge node {} (l1);
%     \end{tikzpicture}
%     \caption{Example directed acyclic graph of two time point survival process.}
%     \end{subfigure}
%     \begin{subfigure}{\linewidth}
%         \begin{tikzpicture}[> = stealth, shorten > = 1pt, auto, node distance = 2cm, inner sep = 0pt,minimum size = 0.5pt, semithick]
%             \tikzstyle{every state}=[
%               draw = white,
%               fill = white
%             ]
%             \node[state] (l0) {$L_0$};
%             \node[state] (a0) [right of=l0] {$A_0 \mid a_0$};
%             \node[state] (c0) [right of=a0] {$C_1^{a_0}$};
%             \node[state] (y1) [right of=c0] {$Y_1^{a_0}$};
%             \node[state] (l1) [right of=y1] {$L_1^{a_0}$};
%             \node[state] (a1) [right of=l1] {$A_1^{a_0} \mid a_1$};
%             \node[state] (c1) [right of=a1] {$C_2^{a_0,a_1}$};
%             \node[state] (y2) [right of=c1] {$Y_2^{a_0,a_1}$};
%             \node[state] (p0) [below of=l0] {$P_0$};
%             \node[state] (b0) [right of=p0] {};
%             \node[state] (b1) [right of=b0] {};
%             \node[state] (b2) [right of=b1] {};
%             \node[state] (p1) [right of=b2] {$P_1^{a_0}$};
%             \node[state] (u0) [below of=b2] {$U$};
            
%             \path[->] (l0) edge node {} (a0);
%             \path[->] (l0) edge node {} (p1);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (c0);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (y1);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (l1);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (c1);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (a1);
%             \path[->] (l0) edge [out=20, in=160, looseness=1.5] node {} (y2);
        
%             \path[->] (a0) edge node {} (p1);
%             \path[->] (a0) edge node {} (c0);
%             \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (y1);
%             \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (l1);
%             \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%             \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%             \path[->] (a0) edge [out=20, in=160, looseness=1.5]  node {} (y2);
            
%             \path[->] (c0) edge node {} (p1);
%             \path[->] (c0) edge node {} (y1);
%             \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (l1);
%             \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%             \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%             \path[->] (c0) edge [out=20, in=160, looseness=1.5]  node {} (y2);
        
%             \path[->] (y1) edge node {} (p1);
%             \path[->] (y1) edge node {} (l1);
%             \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (a1);
%             \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (c1);
%             \path[->] (y1) edge [out=20, in=160, looseness=1.5]  node {} (y2);
            
%             \path[->] (p0) edge node {} (p1);
%             \path[->] (p0) edge node {} (y1);
%             \path[->] (p0) edge node {} (y2);
        
%             \path[->] (p1) edge node {} (y2);
                
%             \path[->] (l1) edge node {} (a1);
%             \path[->] (l1) edge [out=20, in=160, looseness=1.5] node {} (c1);
%             \path[->] (l1) edge [out=20, in=160, looseness=1.5] node {} (y2);
            
%             \path[->] (a1) edge node {} (c1);
%             \path[->] (a1) edge [out=20, in=160, looseness=1.5] node {} (y2);
        
%             \path[->] (c1) edge node {} (y2);
        
%             \path[->] (u0) edge node {} (y1);
%             \path[->] (u0) edge node {} (y2);
%             \path[->] (u0) edge node {} (l0);
%             \path[->] (u0) edge node {} (l1);
%             \end{tikzpicture}
%             \caption{Example single world intervention graph for two time points under intervention on $A_0$ and $A_1$.}
%     \end{subfigure}
%     \caption{Example graphs for survival process described in sec X.}
%     \label{fig:dag_survival}
% \end{figure}

% \subsection{Identifiability conditions}
% For a right-censored survival outcome with time-varying treatment initiation, the following identifiability conditions are required. For all $k$ from 0 to $K$,
% \begin{enumerate}
%     \item \textit{Exchangeability:} $Y^{g, \overline{c}=0}_{k+1} \perp \!\!\! \perp (A_k, C_{k+1}) \mid \overline{X}_k, \overline{A}_{k-1}, \overline{C}_k = \overline{Y}_k = 0$
%     \item \textit{Consistency:} $Y_{k+1} = Y^{g, \overline{c}=0}$\text{ and } $\overline{X}_{k} = \overline{X}^{g, \overline{c}=0}_{k}$ \text{ if } $\overline{A}_k = \overline{a}_k^g$ \text{ and } $\overline{C}_k = 0$
%     \item \textit{Positivity:} $1 > \Pr(A_k = a_k, C_{k+1} = 0 \mid \overline{X}_k = \overline{X}_k, \overline{A}_{k -1} = \overline{a}_{k-1}, \overline{C}_k = \overline{Y}_k = 0) > 0$
% \end{enumerate}

% \subsection{Identification of general loss functions}

% Under time-varying treatment initiation, the expected counterfactual loss for general loss function $L\{Y^{g, \overline{c}=0}_{K+1}, \mu_{\widehat{\beta}}(X^*)\}$ is identified by the functionals
%     \begin{align*}
%         \psi_{\widehat{\beta}} = E_{X_0}\left\{E_{Y_1}\left(Y_1 + \ldots E_{Y_{K}}\left(Y_{K}(1 - Y_{K-1}) + E_{X_K}[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1] \right)\ldots \mid X_{0}, A_{0}=a^g_{0}, D_{test} = 1\right)\mid D_{test} = 1\right\}
%     \end{align*}
% and 
%     \begin{equation*}
%         \psi_{\widehat{\beta}} = \E\left[\frac{I(\overline{A}_K = \overline{a}^g_K)}{\prod_{k=0}^K\Pr(A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1)}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right]
%     \end{equation*}
% in the test set, where the first is a sequence of iterated expectations and the second is an inverse-probability weighted expectation.

% \begin{proof}
%     For the first representation we have 
%     \begin{align*}
%         \psi_{\widehat{\beta}} &= \E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}] \\
%         & = \E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid D_{test} = 1] \\
%         & = \E(\E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid X_0, D_{test} = 1] \mid D_{test} = 1) \\
%         & = \E(\E[L\{Y^{g}, \mu_{\widehat{\beta}}(X^*)\}\mid X_0, A_0 = a^g_0, D_{test} = 1] \mid D_{test} = 1) 
%     \end{align*}
%     where the first line follows from the definition of $\psi_{\widehat{\beta}}$, the second from random sampling of the test set, the third from the law of iterated expectations, and the fourth from the exchangeability condition. Arguing recursively from $k = 0$ to $K$, we can repeatedly invoke iterated expectations and exchanageability to insert $\overline{X}_k$ and $\overline{A}_k = \overline{a}^g_k$, such that
%     \begin{align*}
%         \psi_{\widehat{\beta}} &= E\left\{\E\left(\ldots \E[L\{Y^g, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1]\ldots \mid X_{0}, A_{0}=a^g_{0}, D_{test} = 1\right)\mid D_{test} = 1\right\} \\
%         &= \E\left\{\E\left(\ldots \E[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_K=\overline{a}^g_K, D_{test} = 1]\ldots \mid X_{0}, A_{0}=a^g_{0}, D_{test} = 1\right)\mid D_{test} = 1\right\}
%     \end{align*}
%     where the last line follows by consistency. For the second representation, note that for the inner most expectations we can proceed as previously
%     \begin{align*}
%         & \E(\E[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_k=\overline{a}^g_K, D_{test} = 1] \mid \overline{X}_{K-1}, \overline{A}_{k-1}=\overline{a}^g_{K-1}, D_{test} = 1) \\
%         &= \E\left(\E\left[W_K L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1\right] \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right)\\
%         &= \E\left(W_K \E\left[L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1\right] \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right)\\
%         &= \E\left[W_K L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid \overline{X}_{K-1}, \overline{A}_{K-1}, D_{test} = 1\right]
%     \end{align*}
%     where the second line follows from the definition of conditional expectation, the third removes the constant fraction outside expectation, and the last reverses the law of iterated expectations and where 
%     $$W_K = \frac{I(A_K = a_K^g)}{\Pr(A_K = a_K^g \mid \overline{X}_K, \overline{A}_{K-1}, D_{test} = 1)}$$
%     Arguing recursively from $k = 0$ to $K$, we get
%     \begin{align*}
%         \psi_{\widehat{\beta}} &= \E\left[\frac{I(\overline{A}_K = \overline{a}^g_K)}{\prod_{k=0}^K\Pr(A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1)}L\{Y, \mu_{\widehat{\beta}}(X^*)\} \mid D_{test} = 1\right] 
%     \end{align*}
%     which is the inverse-probability weighted representation with weights equal to 
%     $$W_k = \frac{I(\overline{A}_K = \overline{a}^g_K)}{\prod_{k=0}^K\Pr(A_k = a^g_k \mid \overline{X}_k, \overline{A}_{k-1} = \overline{a}^g_{k-1}, D_{test} = 1)}$$
%     .
% \end{proof}

% \subsection{Plug-in estimation}

\section{Doubly robust estimators} \label{sec:dr}

\subsection{Efficient influence function}
We have shown previously that, under the identifiability conditions of section \ref{sec:identifiability}, the expected counterfactual loss of a generalized loss function $L\{Y^a, \mu(X^*)\}$ is identified by the observed data functional
\begin{equation*}\label{eqn:cl_estimand}
    \psi = \E\left(\E[L\{Y, \mu(X^*)\} \mid X, A=a] \right).
\end{equation*}
In the following theorem, we identify the efficient influence function for $\psi$ under a nonparametric model for the observed data in the test set. 

\begin{theorem}
    The influence function for $\psi$ under a nonparametric model for the observable data $O = (X, A, Y)$ is 
\begin{align*}
    \chi_{P_0}^1 &= \frac{I(A = a)}{\Pr[A = a \mid X]}(L\{Y, \mu(X^*)\} - \E[L\{Y, \mu(X^*)\} \mid X, A=a])  \; + \\
    & \qquad (\E[L\{Y, \mu(X^*)\} \mid X, A=a] - \psi).
\end{align*}
As the influence function under a nonparametric model is always unique, it is also the efficient influence function. 
\end{theorem}


\begin{proof}
To show that $\chi_{P_0}^1$ is the efficient influence function, we will use the well-known fact that the influence function is a solution to 
\begin{equation*}
    \frac{d}{dt} \psi_{P_t}\bigg\vert_{t=0} = \E_{P_0}(\chi_{P_0}^1g_{P_0})
\end{equation*}
where $g_{P_0}$ is the score of the obeservable data under the true law $P_0$ and $P_t$ is a parametric submodel indexed by $t \in [0,1]$ and the pathwise derivative of the submodel is evaluated at $t = 0$ corresponding to the true law $P_0$. Let $h_a(X) = E_{P_0}[L\{Y, \mu(X^*)\} \mid X, A=a]$. Beginning with the left hand side
\begin{align*}
    \frac{d}{dt} \psi_{P_t}\bigg\vert_{t=0} &=\frac{d}{dt} \E_{P_t}\left(\E_{P_t}[L\{Y, \mu(X^*)\} \mid X, A=a] \right)\bigg\vert_{t=0} \\
    &=\frac{\partial}{\partial t} \E_{P_t}\left(\E_{P_0}[L\{Y, \mu(X^*)\} \mid X, A=a] \right)\bigg\vert_{t=0} \;+ \\
    &\qquad  \E_{P_0}\left(\frac{\partial}{\partial t} \E_{P_t}[L\{Y, \mu(X^*)\} \mid X, A=a] \bigg\vert_{t=0} \right) \\
    &=\E_{P_0}\left[\left\{h_a(X) - \psi \right\}g_{X, A, Y}(O)\right] \;+ \\
    &\qquad  \E_{P_0}\left\{\left( \frac{I(A = a)}{\Pr[A = a \mid X]} \bigg[L\{Y, \mu(X^*)\} - h_a(X) \bigg]\right)g_{X, A, Y}(O)\right\} \\
    &= \E_{P_0}\left\{\left(h_a(X) - \psi + \frac{I(A = a)}{\Pr[A = a \mid X]} \bigg[L\{Y, \mu(X^*)\} - h_a(X) \bigg]\right)g_{X, A, Y}(O)\right\} 
\end{align*}
where the first line is the definition, the second line applies the chain rule, the third applies definition of the score, and the last uses linearity of expectations. Returning to original supposition, it follows that the influence function is 
\begin{align*}
    \chi_{P_0}^1 &= \frac{I(A = a)}{\Pr[A = a \mid X]}(L\{Y, \mu(X^*)\} - \E[L\{Y, \mu(X^*)\} \mid X, A=a])  \; + \\
    & \qquad (\E[L\{Y, \mu(X^*)\} \mid X, A=a] - \psi).
\end{align*}
\end{proof}

\subsection{One-step estimator}
Given the efficient influence function above and  random sampling in the test set, the one-step estimator for $\psi$ is given by
\begin{equation*}
    \widehat{\psi}_{DR} = \frac{1}{n_{test}}\sum_{i=1}^n I(D_{test, i} = 1)\widehat{h}_a(X_i) + \frac{I(A_i = a, D_{test, i} = 1)}{\widehat{e}_a(X_i)} \left[ L\{Y_i, \mu(X^*_i)\} - \widehat{h}_a(X_i)\right]
\end{equation*}

\subsection{Asymptotic properties}
In previous sections, the asymptotic properties of $\widehat{\psi}_{CL}$ and $\widehat{\psi}_{IPW}$ follow from standard parametric theory\footnote{after separating estimation of $\mu_\beta(X^*)$ from the evaluation of performance by random partition of test set.}. However, the asymptotic properties of $\widehat{\psi}_{DR}$ are complicated by the estimation of two nuisance functions, $\widehat{h}_a(X)$ and $\widehat{e}_a(X)$, and the fact that, we do not immediately assume a parametric model for either. To simplify the derivation of the large sample properties of $\widehat{\psi}_{DR}$ we begin by defining
$$
H\left(e_a^{\prime}(X), h_a^{\prime}(X)\right)=h_a^{\prime}(X)+\frac{I(A = a)}{e_a^{\prime}(X)}\left[L\left(Y, \mu\left(X^*\right)\right)-h_a^{\prime}(X)\right]
$$
for arbitrary functions $e_a^{\prime}(X)$, and $h_a^{\prime}(X)$. Here we suppress the dependence on being in the test set for ease of exposition, but note that the rest procedes the same if we were to limit our focus to the test set. Note, the doubly robust estimator can be written as $\widehat{\psi}_{DR}=\frac{1}{n} \sum_{i=1}^n H\left(\widehat{e}_a\left(X_i\right), \widehat{h}_a\left(X_i\right)\right)$. We define the probability limits of $\widehat{e}_a(X)$ and $\widehat{h}_a(X)$ as $e_a^*(X)$ and $h_a^*(X)$, respectively. By definition, when $\widehat{e}_a(X)$ and $\widehat{h}_a(X)$ are correctly specified, the limits are  $e_a^*(X)=$ $\operatorname{Pr}[A=a \mid X]$ and $h^*_a(X)=\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]$.

To derive the asymptotic properties of $\widehat{\psi}_{DR}$, we make the following assumptions:

\begin{enumerate}
    \item[D1.] $H(\widehat{e}_a(X), \widehat{h}_a(X))$ and its limit $H\left(e^*_a(X), h^*_a(X)\right)$ fall in a Donsker class.
    \item[D2.]  $\left\|H(\widehat{e}_a(X), \widehat{h}_a(X))-H\left(e^*_a(X), h^*_a(X)\right)\right\| \stackrel{P}{\longrightarrow} 0$.
    \item[D3.] (Finite second moment). $\mathrm{E}\left[H\left(e^*_a(X), h^*_a(X)\right)^2\right]<\infty$.
    \item[D4.] (Model double robustness). At least one of the models $\widehat{e}_a(X)$ or $\widehat{h}_a(X)$ is correctly specified. That is, at least one of $e^*_a(X)=\operatorname{Pr}[A=a \mid X]$ or $h^*_a(X)=\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]$ holds, but not necessarily both.
\end{enumerate}

Assumption D1 is a well-known restriction on the complexity of the functionals $\widehat{e}_a(X)$ and $\widehat{h}_a(X)$. As long as $\widehat{e}_a(X), \widehat{h}_a(X), e^*_a(X)$, and $h^*_a(X)$ are Donsker and all are uniformly bounded then Assumption D1 holds by the Donsker preservation theorem. Many commonly used models such as generalized linear models fall within the Donsker class. This requirement can be further relaxed through sample-splitting, in which case more flexible machine learning algorithms such as random forests, gradient boosting, or neural networks may be used to estimate $\widehat{e}_a(X)$ and $\widehat{h}_a(X)$. 

Using Assumptions D1 through D4, below we prove:
\begin{enumerate}
    \item (Consistency) $\widehat{\psi}_{D R} \stackrel{P}{\longrightarrow} \psi$.
    \item (Asymptotic distribution) $\widehat{\psi}_{D R}$ has the asymptotic representation
    $$
    \sqrt{n}\left(\widehat{\psi}_{D R}-\psi\right)=\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n H\left(e^*_a(X_i), h^*_a(X_i)\right)-\mathrm{E}\left[H\left(e^*_a(X), h^*_a(X)\right)\right]\right)+R e+o_P(1),
    $$
    where
    $$
    R e \leq \sqrt{n} O_P\left(\left\|\widehat{h}_a(X)-\mathrm{E}\left[L\left(Y, \mu(X^*)\right) \mid X, A=a\right]\right\|_2^2 \times\Big\|\widehat{e}_a(X)-\operatorname{Pr}[A=a \mid X]\Big\|_2^2\right) 
    $$
    and thus if $\widehat{h}_a(X)$ and $\widehat{e}_a(X)$ converge at combined rate of at least $\sqrt{n}$ then
    $$
    \sqrt{n}\left(\widehat{\psi}_{D R}-\psi\right) \stackrel{d}{\longrightarrow} N\left(0, \operatorname{Var}\left[H(e^*_a(X), h^*_a(X))\right]\right)
    $$
\end{enumerate}

% 1. 
% 2. $\widehat{\psi}_{D R}$ has the asymptotic representation
% $$
% \sqrt{n}\left(\widehat{\psi}_{D R}-\psi\right)=\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n H\left(e^*_a(X_i), h^*_a(X_i)\right)-\mathrm{E}\left[H\left(e^*_a(X), h^*_a(X)\right)\right]\right)+R e+o_P(1),
% $$
% where
% $$
% R e \leq \sqrt{n} O_P\left(\left\|\widehat{h}_a(X)-\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, D=1\right]\right\|_2^2 \times\|\widehat{e}_a(X)-\operatorname{Pr}[D=1 \mid X]\|_2^2\right) .
% $$
% Theorem 3 gives useful insights into the behaviour of the doubly robust estimator and

\subsubsection{Consistency}
Using the probability limits $e_a^*(X)$ and $h_a^*(X)$ defined previously, the double robust estimator $\widehat{\psi}_{DR}$ converges in probability to 
$$\widehat{\psi}_{DR} \stackrel{P}{\longrightarrow} \E\left[h^*_a(X)+\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right)\right]$$
Here we show that the right-hand side is equal to $\psi$ under assumptions D1-
D4 when either:
\begin{enumerate}
    \item $\widehat{e}_a(X)$ is correctly specified
    \item $\widehat{h}_a(X)$ is correctly specified
\end{enumerate}
First consider the case where $\widehat{e}_a(X)$ is correctly specified, that is $e^*_a(X)=\operatorname{Pr}[A=a \mid X]$, but we do not assume that the limit $h^*_a(X)$ is equal to $\left.\mathrm{E}\left[L\left(Y, g\left(X^*\right)\right) \mid X, A=a\right]\right)$. Recall, as shown previously $\psi = \E\left[\frac{I(A = a)}{\Pr[A = a \mid X]}L(Y, \mu_{\widehat{\beta}}(X^*))\right] $
$$
\begin{aligned}
\widehat{\psi}_{DR} & \stackrel{P}{\rightarrow}  \E\left[h^*_a(X)+\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right)\right] \\
& =\E\left[h^*_a(X)-\frac{I(A = a)}{e^*_a(X)}h^*_a(X)\right]+\psi \\
& =\E\left[\E\left[h^*_a(X)-\frac{I(A = a)}{e^*_a(X)}h^*_a(X) \mid X \right]\right]+\psi \\
& =\E\left[h^*_a(X)-\frac{1}{e^*_a(X)}h^*_a(X) \E\left[I(A = a) \mid X \right]\right]+\psi \\
& =\E\left[h^*_a(X)-\frac{1}{e^*_a(X)}h^*_a(X) \Pr\left[A = a \mid X \right]\right]+\psi \\
& =\E\left[h^*_a(X)-h^*_a(X)\right]+\psi \\
& =\psi .
\end{aligned}
$$
Next consider the case when $\widehat{h}_a(X)$ is correctly specified, that is
$$
h^*_a(X)=\mathrm{E}\left[L\left(Y, g\left(X^*\right)\right) \mid X, A=a\right]
$$
and this time we do not make the assumptions that the limit $e^*_a(X)$ is equal to $\operatorname{Pr}[A=a \mid X]$. Recall, as shown previously $\psi = \E\left[\E\left[L(Y, \mu_{\widehat{\beta}}(X^*))\mid X, A = a\right]\right] $. 

$$
\begin{aligned}
\widehat{\psi}_{DR} & \stackrel{P}{\rightarrow}  \E\left[h^*_a(X)+\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right)\right] \\
&= \E\left[h^*_a(X)\right]+\E\left[\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right)\right] \\
& =\psi+\E\left[\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right)\right] \\
& =\psi+\E\left[\E\left[\frac{I(A = a)}{e^*_a(X)}\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right) \mid X \right]\right] \\
& =\psi+\E\left[\frac{I(A = a)}{e^*_a(X)} \E\left[\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right) \mid X \right]\right] \\
& =\psi+\E\left[\E\left[\left(L\left(Y, \mu\left(X^*\right)\right)-h^*_a(X)\right) \mid X, A=a \right]\right] \\
& =\psi+\E\left[\E\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a  \right] -h^*_a(X) \right] \\
& =\psi+\E\left[h^*_a(X) -h^*_a(X) \right] \\
& =\psi .
\end{aligned}
$$

\subsubsection{Asymptotic distribution}

For a random variable $W$ we define notation
$$
\mathbb{G}_n(W)=\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n W_i-\mathrm{E}[W]\right) .
$$
and thus the asymptotic representation of $\widehat{\psi}_{DR}$ can be written
$$
\begin{aligned}
\sqrt{n}\left(\widehat{\psi}_{D R}-\psi\right)=\mathbb{G}_n &(H(\widehat{e}_a(X), \widehat{h}_a(X)))-\mathbb{G}_n\left(H\left(e^*_a(X), h^*_a(X)\right)\right) \\
& +\mathbb{G}_n\left(H\left(e^*_a(X), h^*_a(X)\right)\right) \\
& +\sqrt{n}(\mathrm{E}[H(\widehat{e}_a(X), \widehat{h}_a(X))]-\psi)
\end{aligned}
$$
where we add and subtract the term $\mathbb{G}_n\left(H\left(e^*_a(X), h^*_a(X)\right)\right)$ and add another zero term in $+\sqrt{n}(\mathrm{E}[H(\widehat{e}_a(X), \widehat{h}_a(X))]-\psi)$. For the first term, Assumption D1 implies
$$
\mathbb{G}_n(H(\widehat{e}_a(X), \widehat{h}_a(X)))-\mathbb{G}_n\left(H\left(e^*_a(X), h^*_a(X)\right)\right)=o_P(1)
$$
Let 
$$
Re=\sqrt{n}(\mathrm{E}[H(\widehat{e}_a(X), \widehat{h}_a(X))]-\psi)
$$
now we have
$$
\sqrt{n}\left(\widehat{\psi}_{DR}-\psi\right)=\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n\left(H\left(e^*_a(X_i), h^*_a(X_i)\right)-\mathrm{E}\left[H\left(e^*_a(X), h^*_a(X)\right)\right]\right)\right)+R e+o_P(1)
$$
Let's try to calculate the upper bound of $Re$. First, note

$$
n^{-1 / 2} Re=
\underbrace{\mathrm{E}\left[\widehat{h}_a(X)\right]}_{R_1}+\underbrace{\mathrm{E}\left[\frac{I(A = a)}{\widehat{e}_a(X)}\left[L\left(Y, \mu\left(X^*\right)\right)-\widehat{h}_a(X)\right]\right]}_{R_2}-\psi.
$$
% The first term $R_1$ can be rewritten as:
% $$
% \begin{aligned}
% R_1 & =\mathrm{E}[\widehat{h}_a(X)] \\
% & =\mathrm{E}[\mathrm{E}[\widehat{h}_a(X) \mid X]] \\
% & =\mathrm{E}[\mathrm{E}[I(D=0) \mid X] \widehat{h}_a(X)] \\
% & =\mathrm{E}[\operatorname{Pr}[D=0 \mid X] \widehat{h}_a(X)] .
% \end{aligned}
% $$
We rewrite term $R_2$ as:
$$
\begin{aligned}
R_2 & =\mathrm{E}\left[\frac{ I(A=a)}{\widehat{e}_a(X)}\left\{L\left(Y, \mu\left(X^*\right)\right)-\widehat{h}_a(X)\right\}\right] \\
& =\mathrm{E}\left[\mathrm{E}\left[\frac{ I(A=a)}{\widehat{e}_a(X)}\left\{L\left(Y, \mu\left(X^*\right)\right)-\widehat{h}_a(X)\right\} \mid X\right]\right] \\
& =\mathrm{E}\left[\frac{1}{\widehat{e}_a(X)} \mathrm{E}\left[\frac{I(A=a)}{\operatorname{Pr}[A=a \mid X]} \operatorname{Pr}[A=a \mid X]\left\{L\left(Y, \mu\left(X^*\right)\right)-\widehat{h}_a(X)\right\} \mid X\right]\right] \\
& =\mathrm{E}\left[\frac{1}{\widehat{e}_a(X)} \mathrm{E}\left[\operatorname{Pr}[A=a \mid X]\left\{L\left(Y, \mu\left(X^*\right)\right)-\widehat{h}_a(X)\right\} \mid X, A=a\right]\right] \\
& =\mathrm{E}\left[\frac{1}{\widehat{e}_a(X)} \operatorname{Pr}[A=a \mid X]\left\{\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]-\widehat{h}_a(X)\right\}\right]
\end{aligned}
$$
% Finally, we rewrite,
% $$
% \begin{aligned}
% \psi & =\mathrm{E}\left[\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right] \mid D=0\right] \\
% & =\frac{1}{\operatorname{Pr}[D=0]} \mathrm{E}\left[I(D=0) \mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]\right] \\
% & =\frac{1}{\operatorname{Pr}[D=0]} \mathrm{E}\left[\mathrm{E}\left[I(D=0) \mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right] \mid X\right]\right] \\
% & =\frac{1}{\operatorname{Pr}[D=0]} \mathrm{E}\left[\operatorname{Pr}[D=0 \mid X] \mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]\right]
% \end{aligned}
% $$
Combining the above gives
$$
\begin{aligned}
n^{-1 / 2} R e & =\mathrm{E}\left[\widehat{h}_a(X)\right]+\mathrm{E}\left[\frac{I(A = a)}{e_a^{\prime}(X)}\left[L\left(Y, \mu\left(X^*\right)\right)-h_a^{\prime}(X)\right]\right]-\psi \\
& =\mathrm{E}\left[\widehat{h}_a(X)\right]+\mathrm{E}\left[\frac{1}{\widehat{e}_a(X)} \operatorname{Pr}[A=a \mid X]\left\{\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]-\widehat{h}_a(X)\right\}\right] \\ 
&- \E\left[\E\left[L(Y, \mu_{\widehat{\beta}}(X^*))\mid X, A = a\right]\right]\\
& =\E\left[\left\{\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]-\widehat{h}_a(X)\right\}\times\left\{\frac{1}{\widehat{e}_a(X)} \operatorname{Pr}[A=a \mid X]-1\right\}\right]
\end{aligned}
$$
Using the Cauchy-Schwartz inequality we get.
$$
\begin{aligned}
Re & \leq \sqrt{n}\left(\mathrm{E}\left[\left\{\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]-\widehat{h}_a(X)\right\}^2\right]\right)^{1 / 2} \\
& \times\left(\mathrm{E}\left[\left\{\frac{1}{\widehat{e}_a(X)} \operatorname{Pr}[A=a \mid X]-1\right\}^2\right]\right)^{1 / 2} \\
\leq & \sqrt{n} O_P\left(\left\|\mathrm{E}\left[L\left(Y, \mu\left(X^*\right)\right) \mid X, A=a\right]-\widehat{h}_a(X)\right\|_2^2 \times\Big\|\widehat{e}_a(X)-\operatorname{Pr}[A=a \mid X]\Big\|_2^2\right)
\end{aligned}
$$

If both models $\widehat{e}_a(X)$ and $\widehat{h}_a(X)$ are correctly specified and converge at a combined rate faster than $\sqrt{n}$, then $R e=o_P(1)$ and
$$
\begin{aligned}
\sqrt{n}\left(\widehat{\psi}_{D R}-\psi\right) & =\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n H\left(\operatorname{Pr}\left[A=a \mid X_i\right], \mathrm{E}\left[L\left(Y, g\left(X^*\right)\right) \mid A=a, X_i\right]\right)\right. \\
& \left.-\mathrm{E}\left[H\left(\operatorname{Pr}[A=a \mid X], \mathrm{E}\left[L\left(Y, g\left(X^*\right)\right) \mid A=a, X\right]\right)\right]\right)+o_P(1)
\end{aligned}
$$
By the central limit theorem,
$$
\sqrt{n}\left(\frac{1}{n} \sum_{i=1}^n H\left(e^*_a(X_i), h^*_a(X_i)\right)-\mathrm{E}\left[H\left(e^*_a(X_i), h^*_a(X_i)\right)\right]\right) \stackrel{d}{\longrightarrow} N\left(0, \operatorname{Var}\left[H\left(e^*_a(X), h^*_a(X)\right)\right]\right)
$$
completing the proof.

\section{Risk calibration curve}\label{sec:calib}
When the outcome is binary, another common metric of model performance is risk calibration. Calibration is a measure of the relibability of the risk estimates produced by the fitted model $\mu_{\widehat{\beta}}(X^*)$. For instance, among a sample of patients who receive a risk prediction of 17\% does the outcome really occur for roughly 17\% of them over the follow up period? This can be nonparametrically evalutated across a range of risks by estimating the so-called ``calibration'' curve, i.e. the observed risk as a function of the predicted risk. For counterfactual predictions the relevant calibration curve is the counterfactual risk that would be observed under intervetion $A=a$ as a function of the predicted risk, or
\begin{equation}\label{eqn:calib_estimand}
    \psi_{\widehat{\beta}} = \E[I(Y^a = 1) \mid \mu_{\widehat{\beta}}(x^*)].
\end{equation}

\subsection{Identification}
Here we show that the counterfactual calibration curve $\psi_{\widehat{\beta}} = \E[I(Y^a = 1) \mid \mu_{\widehat{\beta}}(x^*)]$ is identified using the observed data under the assumptions of section \ref{sec:identifiability}.
\begin{theorem}
     Under conditions A1-A3, the risk calibration curve is identified by the observed data functionals
\begin{equation}\label{eqn:cl_calib_estimand}
    \psi_{\widehat{\beta}} = \E[\E\{I(Y = 1) \mid X, A = a, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1]
\end{equation}
and 
\begin{equation}\label{eqn:ipw_calib_estimand}
    \psi_{\widehat{\beta}} = \E\left[\frac{I(A = a)}{\Pr[A = a \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1]} I(Y=1) \mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right]
\end{equation}
in the test set. 

\end{theorem}

\begin{proof}
    For the first representation we have 
    \begin{align*}
        \psi_{\widehat{\beta}} &= \E[I(Y^a = 1) \mid \mu_{\widehat{\beta}}(x^*)] \\
        & = \E[I(Y^a = 1) \mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1] \\
        & = \E[\E\{I(Y^a = 1) \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1] \\
        & = \E[\E\{I(Y^a = 1) \mid X, A = a, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1] \\
        & = \E[\E\{I(Y = 1) \mid X, A = a, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1]
    \end{align*}
    where the first line follows from the definition of $\psi_{\widehat{\beta}}$, the second from random sampling of the test set, the third from the law of iterated expectations, the fourth from the exchangeability condition A1, and the fifth from the consistency condition A2. Recall that $X^*$ is a subset of $X$. For the second representation, we show that it is equivalent to the first 
    \begin{align*}
        \psi_{\widehat{\beta}} &= \E[\E\{I(Y = 1) \mid X, A = a, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1] \\
        &= \E\left[\E\left\{\frac{I(A = a)}{\Pr[A = a \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1]} I(Y=1) \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right] \\
        % &= \E\left[\frac{I(A = a)}{\Pr[A = a \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1]}\E\left\{ I(Y=1) \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right\}\mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right]\\
        &= \E\left[\frac{I(A = a)}{\Pr[A = a \mid X, \mu_{\widehat{\beta}}(x^*), D_{test} = 1]} I(Y=1) \mid \mu_{\widehat{\beta}}(x^*), D_{test} = 1\right]
    \end{align*}
    where the second line follows from the definition of conditional expectation, and the last reverses the law of iterated expectations.
\end{proof}

\subsection{Estimation}
Unlike previous sections, estimation of the full risk calibration curve using sample analogs of the identified expressions \ref{eqn:cl_calib_estimand} and \ref{eqn:ipw_calib_estimand} is generally infeasible because they are conditional on a continuous risk score. Instead analysts typically perform either kernel or binned estimation of the calibration curve functional. In the case of the counterfactual risk calibration curve under a hypothetical intervention, the expression above suggests modifying these approaches either through the use of inverse probability weights or an outcome model. 


\section{Area under ROC curve}\label{sec:auc}
Another common metric for the performance of a risk prediction model $\mu_\beta(X^*)$ is the area under the receiver operating characteristic (ROC) curve, often referred to as simply the area under the curve (AUC). The AUC can be interpreted as the probability that a randomly sampled observation with the outcome has a higher predicted value than a randomly sampled observation without the outcome. In that sense, it is a measure of the discriminative ability of the model, i.e. the ability to distinguish between cases and noncases. For counterfactual predictions the relevant AUC is the counterfactual AUC that would be observed under intervetion $A=a$, or
\begin{equation}\label{eqn:auc_estimand}
    \psi_{\widehat{\beta}} = \E[I\left(\mu_\beta(X^*_i) > \mu_\beta(X^*_j)\right) \mid Y_i^a = 1, Y_j^a = 0].
\end{equation}

\subsection{Identification}
Here, we show that the counterfactual AUC $\psi_{\widehat{\beta}}$ is identified by the observed data under a modified set of identification conditions, namely:
\begin{enumerate}
    \item[E1.] \textit{Exchangeability.} $Y^a \perp\!\!\!\perp A \mid X$ 
    \item[E2.] \textit{Consistency.} $Y^a = Y$ if $A = a$
    \item[E3.] \textit{Positivity.} (i) $\Pr(A = a | X = x) > 0$ for all $x$ that have positive density in $f(X, A = a)$, (ii) $\mathrm{E}\left[\Pr[Y = 1 | X_i, A = a]\Pr[Y = 0 | X_j, A = a]\right] > 0 $, where $i$ is a random observation that has the outcome and $j$ is random observation without the outcome.
\end{enumerate}


\begin{theorem}
    Under conditions E1-E3, the counterfactual AUC is identified by the observed data functionals in the test set
\begin{equation}\label{eqn:cl_auc_estimand}
    \psi_{\widehat{\beta}} = \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right)m_a(X_i, X_j) \right]}{\mathrm{E}\left[m_a(X_i, X_j) \right]} 
\end{equation}
and 
\begin{equation}\label{eqn:ipw_auc_estimand}
    \psi_{\widehat{\beta}} = \frac{\mathrm{E}\left[\frac{I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\pi_a(X_i, X_j)} \right]}{\mathrm{E}\left[\frac{I\left(Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\pi_a(X_i, X_j)}\right]} 
\end{equation}
where the subscripts $i$ and $j$ denote a random pair of observations from the test set where
\begin{equation*}
    m_a(X_i, X_j) = \operatorname{Pr}\left[Y_i=1 \mid X_i,A_i = a, D_{test,i} = 1\right] \Pr\left[ Y_j=0 \mid X_j, A_j = a, D_{test,j} = 1\right]
\end{equation*}
and 
\begin{equation*}
    \pi_a(X_i, X_j) = \Pr\left[A_i = a \mid X_i, D_{test,i} = 1\right] \Pr\left[A_j = a  \mid X_j, D_{test,j} = 1\right]
\end{equation*}
for a pair of covariate vectors $X_i$ and $X_j$. 
\end{theorem}

\begin{proof}
    For the first representation we have 
$$
\begin{aligned}
 \psi_{\widehat{\beta}}&= \mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \mid Y^a_i=1, Y^a_j=0\right] \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y^a_i=1, Y^a_j=0\right)\right]}{\operatorname{Pr}\left[Y^a_i=1, Y^a_j=0\right]} \\
&= \frac{\mathrm{E}\left[\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y^a_i=1, Y^a_j=0\right) \mid X_i, X_j\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y^a_i=1, Y^a_j=0 \mid X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid X_i, X_j\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid X_i, X_j, A_i = a, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid A_i = a, A_j = a, X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y^a_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y^a_j=0 \mid X_j, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y^a_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y^a_j=0 \mid X_j, A_j = a\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y_j=0 \mid X_j, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y_j=0 \mid X_j, A_j = a\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y_j=0 \mid X_j, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y_i=1 \mid X_i,A_i = a\right] \Pr\left[ Y_j=0 \mid X_j, A_j = a\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right)m_a(X_i, X_j) \right]}{\mathrm{E}\left[m_a(X_i, X_j) \right]}
\end{aligned}
$$

where the first line follows from the definition of $\psi_{\widehat{\beta}}$, the second from the definition of conditional probability, the third from the law of iterated expectations, the fourth from the definition of conditional expectation, the fifth from the exchangeability condition E1, the sixth from independence of potential outcomes, the seventh from the consistency condition E2, the eighth from random sampling of the test set, and the ninth applies the definition of $m_a(X_i, X_j)$. Recall that $X^*$ is a subset of $X$. For the second representation, we will show that it is equivalent to the first. Starting from line five above

$$
\begin{aligned}
\psi_{\widehat{\beta}}&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid X_i, X_j, A_i = a, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y^a_i=1, Y^a_j=0  \mid A_i = a, A_j = a, X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \operatorname{Pr}\left[Y_i=1, Y_j=0  \mid X_i, X_j, A_i = a, A_j = a\right]\right]}{\mathrm{E}\left[\operatorname{Pr}\left[Y_i=1, Y_j=0  \mid A_i = a, A_j = a, X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \frac{\operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]}{\operatorname{Pr}\left[A_i = a, A_j = a \mid X_i, X_j\right]}\right]}{\mathrm{E}\left[\frac{\operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]}{\operatorname{Pr}\left[A_i = a, A_j = a \mid X_i, X_j\right]}\right]} \\
&= \frac{\mathrm{E}\left[\mathrm{E}\left[I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right) \frac{\operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]}{\operatorname{Pr}\left[A_i = a, A_j = a \mid X_i, X_j\right]} \mid X_i, X_j\right]\right]}{\mathrm{E}\left[\mathrm{E}\left[\frac{\operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]}{\operatorname{Pr}\left[A_i=a, A_j = a \mid X_i, X_j\right]} \mid X_i, X_j\right]\right]} \\
&= \frac{\mathrm{E}\left[\frac{I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*)\right)}{\operatorname{Pr}\left[A_i = a \mid X_i\right] \operatorname{Pr}\left[A_j = a \mid X_j\right]} \operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]\right]}{\mathrm{E}\left[\frac{\operatorname{Pr}\left[Y_i=1, Y_j=0, A_i = a, A_j = a \mid X_i, X_j\right]}{\operatorname{Pr}[A_i = a \mid X_i] \Pr[A_j = a \mid X_j]}\right]} \\
& = \frac{\mathrm{E}\left[\frac{I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\operatorname{Pr}\left[A_i = a \mid X_i\right] \operatorname{Pr}\left[A_j = a \mid X_j\right]} \right]}{\mathrm{E}\left[\frac{I\left(Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\operatorname{Pr}[A_i = a \mid X_i] \Pr[A_j = a \mid X_j]}\right]} \\
& = \frac{\mathrm{E}\left[\frac{I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\pi_a(X_i, X_j)} \right]}{\mathrm{E}\left[\frac{I\left(Y_i=1, Y_j=0, A_i = a, A_j = a\right)}{\pi_a(X_i, X_j)}\right]} 
\end{aligned}
$$

   
where the second line follows from consistency $E2$, the third from the definition of conditional probability, the fourth from iterated expectations, the fifth removes the constant fraction outside expectation, the sixth reverses the law of iterated expectations and the last applies random sampling of the test set and the definition of $\pi_a(X_i, X_j)$.
\end{proof}

\subsection{Plug-in estimation}
Using sample analogs for the identified expressions \ref{eqn:cl_auc_estimand} and \ref{eqn:ipw_auc_estimand}, we obtain two plug-in estimators for the counterfactual AUC
    \begin{equation*}
        \widehat{\psi}_{OM}(a) = \frac{\sum_{i \neq j}^n\widehat{h}_a(X_i) (1 - \widehat{h}_a(X_j)) I(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), D_{test, i} = 1,  D_{test, j} = 1) }{\sum_{i \neq j}^n\widehat{h}_a(X_i) (1 - \widehat{h}_a(X_j)) I(D_{test, i} = 1,  D_{test, j} = 1)}
    \end{equation*}
    and 
    \begin{equation*}
        \widehat{\psi}_{IPW}(a) = \frac{\mathlarger{\mathlarger{\sum}}_{i \neq j}^n \dfrac{I\left(\mu_{\widehat{\beta}}(X_i^*)>\mu_{\widehat{\beta}}(X_j^*), Y_i = 1, Y_j = 0, A_i = a, A_j = a, D_{test, i} = 1,  D_{test, j} = 1\right)}{\widehat{e}_a(X_i) \widehat{e}_a(X_j)}}{\mathlarger{\mathlarger{\sum}}_{i \neq j}^n\dfrac{I\left(Y_i = 1, Y_j = 0, A_i = a, A_j = a, D_{test, i} = 1,  D_{test, j} = 1\right)}{\widehat{e}_a(X_i) \widehat{e}_a(X_j)}}
    \end{equation*}
    where $\widehat{m}_a(X_i, X_j) = \widehat{h}_a(X_i) (1 - \widehat{h}_a(X_j))$ and $\widehat{h}_a$ is an estimator for $\operatorname{Pr}[Y_i=1 | X_i,A_i = a, D_{test,i} = 1]$ and where $\widehat{\pi}_a(X_i, X_j) = \widehat{e}_a(X_i) \widehat{e}_a(X_j)$ and $\widehat{e}_a$ is an estimator for $\Pr[A_i = a | X_i, D_{test,i} = 1]$. Here, we call the first plug-in estimator the outcome model estimator $ \widehat{\psi}_{OM}$ and the second the inverse probability weighted estimator $\widehat{\psi}_{IPW}$. 


\section{Additional application details}
The Multi-Ethnic Study on Atherosclerosis (MESA) study is a population-based sample of 6,814 men and women aged 45 to 84 drawn from six communities (Baltimore; Chicago; Forsyth County, North Carolina; Los Angeles; New York; and St. Paul, Minnesota) in the United States between 2000 and 2002. The sampling procedure, design, and methods of the study have been described previously \cite{bild_multi-ethnic_2002}. Study teams conducted five examination visits between 2000 and 2011 in 18 to 24 month intervals focused on the prevalence, correlates, and progression of subclinical cardiovascular disease. These examinations included assessments of lipid-lowering (primarily statins) and other medication use as well as cardiovascular risk factors such as systolic blood pressure, serum cholesterol, cigarette smoking, height, weight, and diabetes. 

Our goal was to emulate a single-arm trial corresponding to the AHA guidelines on initiation of statin therapy for primary prevention of cardiovascular disease in the MESA cohort and use the emulated trial to develop a prediction model for the treatment-naive risk. The AHA guidelines stipulate that patients aged 40 to 75 with serum LDL cholesterol levels between 70 mg/dL and 190 mg/dL and no history of cardiovascular disease should initiate statins if their risk exceeds 7.5\%. Therefore, we considered MESA participants who completed the baseline examination, had no recent history of statin use, no history of cardiovascular disease, and who met the criteria described in the guidelines (excluding the risk threshold) as eligible to participate in the trial. The primary endpoint was time to atherosclerotic cardiovascular disease (ASCVD), defined as nonfatal myocardial infarction, coronary heart disease death, or ischemic stroke. 

Follow up began at the second examination cycle to enable a ``wash out'' period for statin use and to ensure adequate pre-treatment covariates to control confouding. We constructed a sequence of nested trials starting at each examination cycle from exam 2 through exam 5 and pooled the results from all 4 trials into a single analysis and used a robust variance estimator to account for correlation among duplicated participants. In each nested trial, we used the corresponding questionnaire to determine eligibility as well as statin initiators versus non-initiators. Because the exact timing of statin initiation was not known with precision, in each trial, we estimated the start of follow up for initiators and non-initators by drawing a random month between their current and previous examinations. We explored alternative definitions of the start of follow up in sensitivity analyses in the appendix. To mimic the targeted single-arm trial we limited to non-initiators for development of the prediction models.

\subsection{Propensity score models}\label{sec:covs}
In the emulated single arm trial, statin initiation can be viewed as ``non-adherence'' which can be adjusted for by inverse probability weighting, therefore we censored participants when they initiated statins. To calculate the weights, we estimated two logistic regression models: one for the probability of remaining untreated given past covariate history (denominator model) and one for probability of remaining untreated given the selected baseline predictors (numerator model). In the denominator model we included the following covariates:
\begin{itemize}
    \item \textit{Demographic factors} - Age, gender, marital status, education, race/ethnicity, employment, health insurance status, depression, perceived discrimination, emotional support, anger and anxiety scales, and neighborhood score.
    \item \textit{Risk factors} - Systolic and diastolic blood pressure, serum cholesterol levels (LDL, HDL, Triglycerides), hypertension, diabetes, waist circumference, smoking, alcohol consumption, exercise, family history of CVD, calcium score, hypertrophy on ECG, CRP, IL-6, number of pregnancies, oral contraceptive use, age of menopause.
    \item \textit{Medication use} - Anti-hypertensive use, insulin use, daily aspirin use, anti-depressant use, vasodilator use, anti-arryhtmic use. 
\end{itemize}
Time-varying demographic factors and risk factors were lagged such that values from the previous examination cycle were used. 

% \section{Estimating statin-naive risk under time-varying treatment}
